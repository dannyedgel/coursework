%%% Econ710: Econometrics
%%% Spring 2020
%%% Danny Edgel
%%%
% Due on Canvas Tuesday, March 9th, 11:59pm Central Time
%%%

%%%
%							PREAMBLE
%%%

\documentclass{article}

%%% declare packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{bm}
\usepackage{bbm}
\usepackage{changepage}
\usepackage{centernot}
\usepackage{color}
\usepackage{courier}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[shortlabels]{enumitem}
\usepackage{boondox-cal}
\usepackage{fancyhdr}
	\fancyhf{} % sets both header and footer to nothing
	\renewcommand{\headrulewidth}{0pt}
    \rfoot{Edgel, \thepage}
    \pagestyle{fancy}
	
%%% define shortcuts for set notation
\newcommand{\N}{\mathcal{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\union}{\bigcup}
\newcommand{\intersect}{\bigcap}
\newcommand{\lmt}{\underset{x\rightarrow\infty}{\text{lim }}}
\newcommand{\neglmt}{\underset{n\rightarrow-\infty}{\text{lim }}}
\newcommand{\zerolmt}{\underset{x\rightarrow 0}{\text{lim }}}
\newcommand{\usmax}{\underset{1\leq k \leq n}{\text{max }}}
\newcommand{\usmin}[1]{\underset{#1}{\text{min }}}
\newcommand{\intinf}{\int_{-\infty}^{\infty}}
\newcommand{\olx}[1]{\overline{X}_{#1}}
\newcommand{\oly}[1]{\overline{Y}_{#1}}
\newcommand{\olz}[1]{\overline{Z}_{#1}}
\newcommand{\est}[1]{\frac{1}{#1}\sum_{i=1}^{#1}}
\newcommand{\sumn}{\sum_{i=1}^{n}}
\newcommand{\loge}[1]{\text{log}\left(#1\right)}
\renewcommand{\tilde}[1]{\widetilde{#1}}
\newcommand{\tb}{\tilde{\beta}}
\renewcommand{\Pr}[1]{\text{Pr}\left(#1\right)}
\newcommand{\bols}{\hat{\beta}^{OLS}}
\newcommand{\bhat}{\hat{\beta}}
\newcommand{\ahat}{\hat{\alpha}}
\newcommand{\vhat}{\hat{\varepsilon}}
\newcommand{\vols}{\hat{\varepsilon}_{OLS}}
\newcommand{\one}[1]{\mathbbm{1}\left\{#1\right\}}
\newcommand{\tr}[1]{\text{tr}\left(#1\right)}
\newcommand{\pfrac}[2]{\left(\frac{#1}{#2}\right)}
\newcommand{\bcls}{\tilde{\beta}_{CLS}}
\renewcommand{\L}{\mathcal{L}}
\newcommand{\vt}{\tilde{\varepsilon}}
\renewcommand{\Pr}[1]{Pr\left(#1\right)}
\newcommand{\biv}{\bhat^{IV}}
\newcommand{\xbar}{\overline{X}}
\newcommand{\ybar}{\overline{Y}}
\newcommand{\zbar}{\overline{Z}}
\newcommand{\eps}{\varepsilon}
\newcommand{\esti}{\frac{1}{T_i-1}\sum_{t=1}^{T_i}}
\DeclareRobustCommand{\bbone}{\text{\usefont{U}{bbold}{m}{n}1}}

\newcommand{\E}[1]{\mathbb{E}\left[#1\right]}% expected value
\renewcommand{\exp}[1]{\E\left[#1\right]}

\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}


%%% define column vector command (from Michael Nattinger)
\newcount\colveccount
\newcommand*\colvec[1]{
        \global\colveccount#1
        \begin{pmatrix}
        \colvecnext
}
\def\colvecnext#1{
        #1
        \global\advance\colveccount-1
        \ifnum\colveccount>0
                \\
                \expandafter\colvecnext
        \else
                \end{pmatrix}
        \fi
}

\makeatletter
\let\amsmath@bigm\bigm

\renewcommand{\bigm}[1]{%
  \ifcsname fenced@\string#1\endcsname
    \expandafter\@firstoftwo
  \else
    \expandafter\@secondoftwo
  \fi
  {\expandafter\amsmath@bigm\csname fenced@\string#1\endcsname}%
  {\amsmath@bigm#1}%
}


%________________________________________________________________%

\begin{document}

\lstset{language=Matlab,%
    %basicstyle=\color{red},
    breaklines=true,%
    morekeywords={matlab2tikz},
    keywordstyle=\color{blue},%
    morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},
    identifierstyle=\color{black},%
    stringstyle=\color{mylilas},
    commentstyle=\color{mygreen},%
    showstringspaces=false,%without this there will be a symbol in the places where there is a space
    numbers=left,%
    numberstyle={\tiny \color{black}},% size of the numbers
    numbersep=9pt, % this defines how far the numbers are from the text
    emph=[1]{for,end,break},emphstyle=[1]\color{red}, %some words to emphasise
    %emph=[2]{word1,word2}, emphstyle=[2]{style},    
}

\title{	Problem Set \#6 }
\author{ 	Danny Edgel 										\\ 
			Econ 710: Economic Statistics and Econometrics II	\\
			Spring 2021											\\
		}
\maketitle\thispagestyle{empty}

%%%________________________________________________________________%%%

\noindent\textit{Discussed and/or compared answers with Sarah Bass, Emily Case, Katherine Kwok, Michael Nattinger, and Alex Von Hafften}
 \\

%%%________________________________________________________________%%%

\section*{Question 1}

\begin{enumerate}[(i)]
	\item The direct representation of the sample average is:
		\[
			\mu_0 = \frac{1}{n}\sumn \frac{1}{T_i}\sum_{t=1}^{T_i} Y_{it}
		\]
		Since $1_i$ contains $T_i$ elements, ${1_i'1_i=T_i}$, and ${1_i'Y_i=\sum_{t=1}^{T_i}Y_i}$. It is clear, then, that
		\[
			\E{\hat{\mu}_{OLS}} = \frac{\sumn 1_i'Y_i}{\sumn1_i'1_i}
		\]
	
	
	\item We can solve for the variance of $\hat{\mu}_{IV}$ as follows:
		\[
			Var(\hat{\mu}_{IV})	= Var\left(\frac{\sumn Z_i'Y_i}{\sumn Z_i'1_i}\right) = \frac{\sumn Z_i'Var(Y_i)Z_i}{\left(\sumn Z_i'1_i\right)^2}	
		\]
		Where:
		\begin{align*}
						Var(Y_i) 	&= Var(\mu_0 + \alpha_i + \varepsilon_{it}) = Var(\alpha_i) + Var(\varepsilon_{it}) + 2Cov(\alpha_i,\varepsilon_{it})	\\
			\Rightarrow \Omega_i	&= \sigma^2_\alpha1_i1_i' + \sigma^2I_{T_i}
		\end{align*}
	
	
	\item To determine how we can show that ${Var(\hat{\mu}_{IV}\geq\left(\sumn 1_i'\Omega_i^{-1}1_i\right)^{-1}}$, we simply need to find that the following inequality holds:
		\[
			\left(\sumn Z_i'1_i\right)^2 \leq \left(\sumn Z_i'\Omega_iZ_i\right)\left(\sumn 1_i'\Omega_i^{-1}1_i\right)
		\]
		Once this inequality is established, it follows that:
		{\small \[
			Var(\hat{\mu}_{IV})	= 		\frac{\sumn Z_i'Var(Y_i)Z_i}{\left(\sumn Z_i'1_i\right)^2}
								\geq 	\frac{\sumn Z_i'Var(Y_i)Z_i}{\left(\sumn Z_i'\Omega_iZ_i\right)\left(\sumn 1_i'\Omega_i^{-1}1_i\right)}
								= 		\left(\sumn 1_i'\Omega_i^{-1}1_i\right)^{-1}
		\] }
		We can establish the inquality using the Cauchy-Schwarz inequality:
		\[
			\left(\sumn Z_i'1_i\right)^2 = 		\left(\sumn Z_i'\Omega^{1/2}\Omega^{-1/2}1_i\right)^2  					
										 \leq 	\left(\sumn Z_i'\Omega_iZ_i\right)\left(\sumn 1_i'\Omega_i^{-1}1_i\right)
		\]
		This variance is achieved by ${\overline{Z}_i=\Omega_i^{-1}1_i}$
		
	\item If $T_i=T$ for all $i$ (i.e., the panel is balanced), then the GLS estimator weights by the entries of $\Sigma^{-1}$, where:
		\[
			\Sigma^{-1} = \frac{1}{\sigma^2}\left(I_T - \frac{\sigma^2_\alpha T}{\sigma^2 + \sigma^2_T}\frac{1_i1_i'}{T}\right)
		\]
		Then, the optimal instrument for GLS is:
		\[
			\overline{Z}_i	= \Sigma^{-1}1_i = \frac{1_i}{\sigma^2}\left(1 - \frac{\sigma^2_\alpha T}{\sigma^2 + \sigma^2_T}\right)
							= \frac{1_i}{\sigma^2 + \sigma^2T}
		\]
		This instrument cancels out in the estimator for $\mu_0$, yielding the OLS estimator:
		\[
			\hat{\mu}_{GLS} = \frac{\sumn \overline{Z}_i'Y_i}{\sumn\overline{Z}_i'1_i} 
							= \frac{\sumn \frac{1}{\sigma^2 + \sigma^2_T}1_i'Y_i}{\sumn\frac{1}{\sigma^2 + \sigma^2_T}1_i'1_i} 
							= \frac{\sumn 1_i'Y_i}{\sumn1_i'1_i} = \hat{\mu}_{OLS}
		\]
		Thus, if the panel is balanced, OLS and GLS are identical.
	
	
	\item First, note that:
		\[
			\overline{Y} = \frac{1}{T_i}\sum{t=1}^{T_i}\mu_0 + \alpha_i + \varepsilon_{it} = \mu_0 + \alpha_i + \frac{1}{T_i}\sum{t=1}^{T_i}\varepsilon_{it}
		\]
		And let $\overline{\varepsilon} = \frac{1}{T_i}\sum{t=1}^{T_i}\varepsilon_{it}$. Then,
		\begin{align*}
			\E{\hat{\sigma}_i^2} 	&= \frac{1}{T_i-1}\sum_{t=1}^{T_i}\E{(\mu_0 + \alpha_i + \eps_{it}-\mu_0 - \alpha_i - \overline{\eps})^2}	\\
									&= \frac{1}{T_i-1}\sum_{t=1}^{T_i}\E{(\eps_{it} - \overline{\eps})^2}										\\
									&= \frac{1}{T_i-1}\sum_{t=1}^{T_i}\E{(\eps_{it} - \overline{\eps})\eps_{it}}								\\
									&= \frac{1}{T_i-1}\sum_{t=1}^{T_i}\E{\eps_{it}^2} - \esti\E{\eps_{it}\overline{\eps})}						\\
									&= \frac{1}{T_i-1}\sum_{t=1}^{T_i}\E{\eps_{it}^2} - \frac{1}{T_i(T_i-1)}\sum_{t=1}^{T_i}\E{\eps_{it}^2}
										- \frac{1}{T_i(T_i-1)}\sum_{t=1}^{T_i}\sum_{s\neq t}^{T_i}\E{\eps_{it}\eps_{is}}						\\
									&= \frac{1}{T_i-1}\sum_{t=1}^{T_i}\sigma^2 - \frac{1}{T_i(T_i-1)}\sum_{t=1}^{T_i}\sigma^2					\\
									&= \sigma^2
		\end{align*}
	
	
	\item 
	
	
	\item 
	
	
\end{enumerate}


%%%________________________________________________________________%%%

\section*{Question 2}

\begin{enumerate}[(i)]
	\item 
	

	\item 
	
	
\end{enumerate}


%%%________________________________________________________________%%%

\section*{Question 3}
The table below presents the results of the simulations.\footnote{See the attached .do file for the code used to generate this table.} As you can see, the pooled OLS estimator of $\beta_0$ is substantially biased upward. An intuitive but less clearly apparent result is that both the fixed effect estimation of $\beta_0$ is generally efficient but much more efficient for larger $n$ and no autocorrelation.
\begin{center}
	\input{q3.tex}
\end{center}




%%%________________________________________________________________%%%





\end{document}








