%%% Econ710: Econometrics
%%% Spring 2020
%%% Danny Edgel
%%%
% Due on Canvas Tuesday, April 13th, 11:59pm Central Time
%%%

%%%
%							PREAMBLE
%%%

\documentclass{article}

%%% declare packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{bm}
\usepackage{bbm}
\usepackage{changepage}
\usepackage{centernot}
\usepackage{color}
\usepackage{courier}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[shortlabels]{enumitem}
\usepackage{boondox-cal}
\usepackage{fancyhdr}
	\fancyhf{} % sets both header and footer to nothing
	\renewcommand{\headrulewidth}{0pt}
    \rfoot{Edgel, \thepage}
    \pagestyle{fancy}
	
%%% define shortcuts for set notation
\newcommand{\N}{\mathcal{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\union}{\bigcup}
\newcommand{\intersect}{\bigcap}
\newcommand{\lmt}{\underset{x\rightarrow\infty}{\text{lim }}}
\newcommand{\neglmt}{\underset{n\rightarrow-\infty}{\text{lim }}}
\newcommand{\zerolmt}{\underset{x\rightarrow 0}{\text{lim }}}
\newcommand{\usmax}{\underset{1\leq k \leq n}{\text{max }}}
\newcommand{\usmin}[1]{\underset{#1}{\text{min }}}
\newcommand{\intinf}{\int_{-\infty}^{\infty}}
\newcommand{\olx}[1]{\overline{X}_{#1}}
\newcommand{\oly}[1]{\overline{Y}_{#1}}
\newcommand{\olz}[1]{\overline{Z}_{#1}}
%\newcommand{\est}[1]{\frac{1}{#1}\sum_{i=1}^{#1}}
\newcommand{\est}[1]{\frac{1}{\lowercase{#1}}\sum_{i=1}^{\lowercase{#1}}}
\newcommand{\sumn}{\sum_{i=1}^{n}}
\newcommand{\loge}[1]{\text{log}\left(#1\right)}
\renewcommand{\tilde}[1]{\widetilde{#1}}
\newcommand{\tb}{\tilde{\beta}}
\renewcommand{\Pr}[1]{\text{Pr}\left(#1\right)}
\newcommand{\bols}{\hat{\beta}^{OLS}}
\newcommand{\bhat}{\hat{\beta}}
\newcommand{\ahat}{\hat{\alpha}}
\newcommand{\ehat}{\hat{\varepsilon}}
\newcommand{\vols}{\hat{\varepsilon}_{OLS}}
\newcommand{\one}[1]{\mathbbm{1}\left\{#1\right\}}
\newcommand{\tr}[1]{\text{tr}\left(#1\right)}
\newcommand{\pfrac}[2]{\left(\frac{#1}{#2}\right)}
\newcommand{\bcls}{\tilde{\beta}_{CLS}}
\renewcommand{\L}{\mathcal{L}}
\newcommand{\vt}{\tilde{\varepsilon}}
\renewcommand{\Pr}[1]{Pr\left(#1\right)}
\newcommand{\biv}{\bhat^{IV}}
\newcommand{\xbar}{\overline{X}}
\newcommand{\ybar}{\overline{Y}}
\newcommand{\zbar}{\overline{Z}}
\newcommand{\eps}{\varepsilon}
\newcommand{\esti}{\frac{1}{T_i-1}\sum_{t=1}^{T_i}}
\newcommand{\oinv}{\Omega^{-1}}
\newcommand{\olg}{\overline{g}_n}
\DeclareRobustCommand{\bbone}{\text{\usefont{U}{bbold}{m}{n}1}}

\newcommand{\E}[1]{\mathbb{E}\left[#1\right]}% expected value
\renewcommand{\exp}[1]{\E\left[#1\right]}

\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}


%%% define column vector command (from Michael Nattinger)
\newcount\colveccount
\newcommand*\colvec[1]{
        \global\colveccount#1
        \begin{pmatrix}
        \colvecnext
}
\def\colvecnext#1{
        #1
        \global\advance\colveccount-1
        \ifnum\colveccount>0
                \\
                \expandafter\colvecnext
        \else
                \end{pmatrix}
        \fi
}

\makeatletter
\let\amsmath@bigm\bigm

\renewcommand{\bigm}[1]{%
  \ifcsname fenced@\string#1\endcsname
    \expandafter\@firstoftwo
  \else
    \expandafter\@secondoftwo
  \fi
  {\expandafter\amsmath@bigm\csname fenced@\string#1\endcsname}%
  {\amsmath@bigm#1}%
}


%________________________________________________________________%

\begin{document}

\lstset{language=Matlab,%
    %basicstyle=\color{red},
    breaklines=true,%
    morekeywords={matlab2tikz},
    keywordstyle=\color{blue},%
    morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},
    identifierstyle=\color{black},%
    stringstyle=\color{mylilas},
    commentstyle=\color{mygreen},%
    showstringspaces=false,%without this there will be a symbol in the places where there is a space
    numbers=left,%
    numberstyle={\tiny \color{black}},% size of the numbers
    numbersep=9pt, % this defines how far the numbers are from the text
    emph=[1]{for,end,break},emphstyle=[1]\color{red}, %some words to emphasise
    %emph=[2]{word1,word2}, emphstyle=[2]{style},    
}

\title{	Problem Set \#10 }
\author{ 	Danny Edgel 										\\ 
			Econ 710: Economic Statistics and Econometrics II	\\
			Spring 2021											\\
		}
\maketitle\thispagestyle{empty}

%%%________________________________________________________________%%%

\noindent\textit{Discussed and/or compared answers with Sarah Bass, Emily Case, Katherine Kwok, Michael Nattinger, and Alex Von Hafften}

% Chapter 22: Exercise 22.1
%
% Chapter 23: Exercises 23.1, 23.2, 23.7, 23.8
%
% Chapter 24: Exercises 24.3, 24.4, 24.5, 24.14

%%%________________________________________________________________%%%

\section*{Exercise 22.1}

\begin{enumerate}[(a)]
	\item The conditional CDF of $Y$ is $Pr(Y\leq y|X=x)$. Given our model, we can solve:
		\[
			Pr(Y\leq y|X=x) = Pr(x'\theta + e\leq y|X=x) = Pr(e\leq y - x'\theta|X=x) = F(y-x'\theta)
		\]
	
	\item Since the distribution of $Y$ is known, we can solve for $\theta$ with MLE. Thus,
		\begin{align*}
			\rho(Y,X,\theta)	&= -\loge{f(Y|X,\theta)} = -\loge{f(y-x'\theta)}	\\
			\phi(Y,X\theta)		&= \frac{\partial}{\partial\theta}\rho(Y,X,\theta) = -\left(\frac{f'(y-x'\theta)}{f(y-x'\theta)}\right)x
		\end{align*}
	
	\item The asymptotic distribution of $\hat{\theta}$ is given by:
		\[
			\sqrt{n}(\hat{\theta}-\theta_0) \rightarrow_d \N\left(0,Q^{-1}\Omega Q^{-1}\right)
		\]
		Where:
		\begin{align*}
					Q		&= \E{\frac{\partial^2}{\partial\theta\partial\theta'}\rho_i(\theta)} = \E{\left(\frac{f'(e_i)^2}{f(e_i)^2}\right)x_ix_i'}		\\
					\Omega 	&= \E{\phi_i\phi_i'} = \E{\left(\frac{\partial}{\partial\theta}\rho_i\right)\left(\frac{\partial}{\partial\theta'}\rho_i'\right)}	
								= \E{\frac{\partial^2}{\partial\theta\partial\theta'}\rho_i} = Q																\\
			\Rightarrow V	&= Q^{-1}\Omega Q^{-1} = Q^{-1} = \E{\left(\frac{f'(e_i)^2}{f(e_i)^2}\right)^{-1}(x_ix_i')^{-1}}
		\end{align*}
	
\end{enumerate}

%%%________________________________________________________________%%%

\section*{Exercise 23.1}

\begin{enumerate}[(a)]
	\item The conditional mean is not linear in $\theta$, since $\E{Y} = \text{exp}(\theta)$. Thus, this is a nonlinear regression model.
	
	\item Yes. We can run OLS on the model as-is, treating $\text{exp}(\theta)$ as our parameter of interest, then transform it post-estimation by taking logs.
	
	\item My answer to part (b) is exactly non-linear least squares, with ${m(\theta)=\text{exp}(\theta)}$.
	
\end{enumerate}

%%%________________________________________________________________%%%

\section*{Exercise 23.2}

We can rewrite the model as:
\[
	Y = 	\begin{cases}
				\left(\lambda\beta + \lambda\beta_1 X + \lambda\eps  + 1\right)^{1/\lambda},	\lambda\neq 0	\\
				e^{\beta_0 + \beta_1X + \eps},												 	\lambda = 0
			\end{cases}
\]
The model is clearly not linear in $(\lambda,\beta_0,\beta_1)$ when $\lambda\neq0$. However, in the ${\lambda=0}$ case, the model is linear with $\loge{Y}$ as a dependent variable. Thus, we can run OLS and transform the parameters post-estimation. However, this makes the model linear in $(\beta_0,\beta_1)$, but not $\lambda$.

%%%________________________________________________________________%%%

\section*{Exercise 23.7}
Given that a consistent estimator for the variance of $\theta$, $\hat{V}$, has already been obtained, \textbf{what would the variance of $m(X,\theta)$ be given the variance of $\theta$? think on this more}



%%%________________________________________________________________%%%

\section*{Exercise 23.8}
The results of the nonlinear least squares CES estimation using an alternative measure are displayed below.\footnote{This table is generated using the attached do file.} Point estimates for each parameter except for $\beta$ are similar across the two tables, but $\beta$ is wildly different. Standard errors are lower for every parameter. 
\begin{center}
	\input{table23_8.tex}
\end{center}


%%%________________________________________________________________%%%

\section*{Exercise 24.3}
We can simplify:
\[
	\E{\phi(Y-\theta)} = \E{\tau - \one{\theta<0}} = \tau - \E{\one{\theta<0}}
\]
$\E{\phi(Y-\theta)}=0$ if and only if $\theta=\tau$. Thus, $\theta$ is the $\tau^{\text{th}}$ quantile of $Y$.

%%%________________________________________________________________%%%

\section*{Exercise 24.4}

\begin{enumerate}[(a)]
	\item The two moments are equivalent:
		\begin{align*}
			\E{Y|X}			&= \E{X'\beta + e|X} 			= X'\beta	\\
			\text{med}[Y|X]	&= \text{med}[X'\beta + e|X]	= X'\beta
		\end{align*}
	
	\item OLS and LAD estimate the same coefficient because the errors are symmetrically distributed about their mean.
	
	\item We would prefer LAD if we sought to find an accurate prediction of a single draw from a skewed distribution, since LAD is robust to influential observations. We would prefer OLS if we wanted to estimate the mean but were either indifferent to outliers or our estimates aren't materially influenced by outliers.
	
\end{enumerate}


%%%________________________________________________________________%%%

\section*{Exercise 24.5}
Not necessarily. If the distribution of the errors is heavily asymmetric, then OLS will more accurately predict the conditional mean of $Y$ (thus generating a higher $R^2$), but it will not necessarily yield more desirable predictions. Whether LAD or OLS  is preferable depends on the model's purpose.

%%%________________________________________________________________%%%

\section*{Exercise 24.14}
The results of the quantile regression for a set of quantiles are below.\footnote{See the attached do file for the code that generated this plot.} Interpretation of these results is dubious and difficult. Each line represents the relationship between education and wages, conditional on an individual remaining in their quantile despite the increase in their wages.
\begin{center}
	\includegraphics[width=\textwidth]{fig24_14.png}
\end{center}

%%%________________________________________________________________%%%





\end{document}








