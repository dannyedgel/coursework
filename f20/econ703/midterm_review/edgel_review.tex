%%% Econ703: Math Camp
%%% Fall 2020
%%% Danny Edgel
%%%
% Midterm: 01 September 2020
%%%

%%%
%							PREAMBLE
%%%

\documentclass{article}

%%% declare packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{bm}
\usepackage{changepage}
\usepackage{centernot}
\usepackage{graphicx}
\usepackage{fancyhdr}
	\fancyhf{} % sets both header and footer to nothing
	\renewcommand{\headrulewidth}{0pt}
    \rfoot{Edgel, \thepage}
    \pagestyle{fancy}
	
%%% define shortcuts for set notation
\newcommand{\intersect}{\bigcap}
\newcommand{\union}{\bigcup}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\lmt}{\underset{x\rightarrow\infty}{\text{lim }}}
\newcommand{\xlmt}{\underset{x\rightarrow x_n}{\text{lim }}}
\newcommand{\neglmt}{\underset{x\rightarrow-\infty}{\text{lim }}}
\newcommand{\zerolmt}{\underset{x\rightarrow 0}{\text{lim }}}
\newcommand{\usmax}{\underset{1\leq k \leq n}{\text{max }}}

%%% define column vector command (from Michael Nattinger)
\newcount\colveccount
\newcommand*\colvec[1]{
        \global\colveccount#1
        \begin{pmatrix}
        \colvecnext
}
\def\colvecnext#1{
        #1
        \global\advance\colveccount-1
        \ifnum\colveccount>0
                \\
                \expandafter\colvecnext
        \else
                \end{pmatrix}
        \fi
}

\makeatletter
\let\amsmath@bigm\bigm

\renewcommand{\bigm}[1]{%
  \ifcsname fenced@\string#1\endcsname
    \expandafter\@firstoftwo
  \else
    \expandafter\@secondoftwo
  \fi
  {\expandafter\amsmath@bigm\csname fenced@\string#1\endcsname}%
  {\amsmath@bigm#1}%
}


%________________________________________________________________%

\begin{document}

\title{Midterm Review}
\author{ 	Danny Edgel 							\\ 
			Econ 703: Mathematical Economics I		\\
			Fall 2020								\\
		}
\maketitle\thispagestyle{empty}


%%%________________________________________________________________%%%

\section{Lecture 1}

\subsection{Logical Operators}
And/or statements ($\land$/$\lor$), if/then statements ($\Rightarrow$,$\iff$), and negation ($\neg$)

\subsection{Methods of proof}
\begin{itemize}
	\item Direct (aka Deductive): directly show that if $P$ is true, then we can "deduce" that $Q$ is also true
	
	\item Contrapositive: Instead of showing $P\Rightarrow Q$, show $\neg Q\Rightarrow\neg P$ (direct proof of the negation of the modus ponens)
	
	\item Contradiction: Show that if $P$ is true, then $Q$ being false yields a contradiction
	
	\item Induction: Proving that a statement $P$ holds for all natural numbers, performed in two steps: the base step and the induction step. Example: $\forall n\in\N$, $\sum_1^n n=\frac{n(n+1)}{2}$
		\begin{enumerate}
			\item The base step: $P(1)$ holds: $\frac{1(1+1)}{2}=\frac{2}{2}=1$
			\item The induction step: $P(n+1)=P(n)$: 
				\[
					P(n+1)=\frac{n(n+1)}{2}+n+1=\frac{n^2+3n+2)}{2}=\frac{(n+1)(n+2)}{2}
				\]
		\end{enumerate}
\end{itemize}

\subsection{Set Operations}
Union ($\bigcup$), Intersection ($\bigcap$), Subset ($\subset$), complement ($^c$), and difference ($\setminus$)
\medskip \\
De Morgan's Laws:
\begin{align*}
	(A\bigcap B)^c	&= A^c\bigcup B^c 	\\
	(A\union B)^c 	&= A^c\intersect B^c
\end{align*}

\subsection{Cardinality}
\textbf{Cardinality}: The size of a set 
\smallskip \\
\textbf{Numerical Equivalence}: The elements of each set can be uniquely matched up and paired off 
\smallskip \\
\textbf{Finite}: Being numerically equivalent to $J_n=\{1,2,...,n\}$. $J_n$'s cadinality is $n$ 
\smallskip \\
\textbf{Infinite}: Not being finite 
\smallskip \\
\textbf{Countable}: Being numerically equivalent to $\N$
\smallskip  \\
\textbf{Uncountable}: Being infinite and not countable
\medskip \\
Common Examples: 
\smallskip \\
\indent \textbf{Countable sets}: $\N$, $\Z$, $\Z\setminus\N$, $\Q$
\smallskip  \\
\indent \textbf{Uncountable}: $2^\N$ (Set of all subsets of $\N$)


%%%________________________________________________________________%%%

\section{Lecture 2}

\subsection{Metric Spaces}
Distance/matrix functions: let $X$ be a metric space  with distance function $d$. Then the following holds $\forall x,y,z\in X$:
\begin{itemize}
	\item Nonnegativity: $d(x,y)\geq 0$, where $d(x,y)=0\iff x=y$
	
	\item Symmetry: $d(x,y)=d(y,x)$
	
	\item Triangle Inequality:$d(x,y)\leq d(x,z) + d(z,y)$
\end{itemize}

\subsection{Convergence in Metric Spaces}
Sequences: $x:\N\rightarrow X$ is a sequence in metric space $(X,d)$, written as $\{x_n\}$, where $x_n=s(n)$. $\{x_n\}$ \textbf{converges} to $x\in X$ if:
\[
	\forall\varepsilon>0,\exists N(\varepsilon)>0\text{ s.t. }\forall n>N(\varepsilon)\text{, }d(x_n,x)<\varepsilon
\]
This is written as $x_n\rightarrow x$ or $\lmt x_n=x$.
\medskip \\
\textbf{Convergence Theorems}
\begin{itemize}
	\item A sequence $\{x_n\}$ in a metric space $(X,d)$ has at most one limit
	
	\item If, for some $\{x_n\}$, $x_n\rightarrow x$, then any \textbf{subsequence} $\{x_{n_k}\}$ also converges to $x$ as $k\rightarrow\infty$. (If $\{x_n\}$ does not converge, then this theorem doesn't tell us anything about its subsequences)
	
	\item Every convergent sequence in a metric space is \textbf{bounded}. A subset $S\subset X$ in a metric space $(X,d)$ is bounded if
		\[
			\exists x\in X,\beta\in\R\text{ s.t. }\forall s\in S\text{, }d(x,s)<\beta
		\]
		
	\item Limits preserve weak inequality: If $x_n\rightarrow x\in\R$, $y_n\rightarrow y\in\R$ and $x_n\leq y_n$ $\forall n\in\N$, then $x\leq y$
	
	\item If $x_n\rightarrow x\in\R$ and $y_n\rightarrow y\in\R$, then:
		\begin{itemize}
			\item $x_n + y_n\rightarrow x+y$, $x_n-y_n\rightarrow x-y$
			\item $x_n y_n\rightarrow xy$
			\item $\frac{x_n}{y_n}\rightarrow\frac{x}{y}$ (if $y\neq 0$ and $y_n\neq 0$ $\forall n$
		\end{itemize}
		
	\item The last two theorems hold for elements of $\R^m$
\end{itemize}

\subsection{Bolzano-Weierstrass Theorem}
Every bounded real sequence contains at least one convergent subsequence.
\smallskip \\
\indent \textit{Lemma 1 (Monotone Convergence Theorem).} Every increasing sequence of real numbers that is bounded above converges. Every decreasing sequence of real numbers that is bounded below converges.
\smallskip \\
\indent \textit{Lemma 2.} Every real swquence contains either a decreasing subsequence of increasing subsequence (and possible both).

\subsection{Infinite Sums}
Given a real sequence $\{x_n\}$, the infinite sum of its terms is \textit{well-defined} if the sequence of partial sums, $\{S_n\}=\sum_{i=1}^n x_i$, converges.
\smallskip \\
If $S_n\rightarrow S$, we write:
\[
	\sum_{i=1}^\infty x_i=S
\]

%%%________________________________________________________________%%%

\section{Lecture 3}

\subsection{Open \& Closed Sets}
Let $(X,d)$ be a metric space.
\smallskip\\
A set $A\subset X$ is \textbf{open} if:
\[
	\forall x\in A\text{, }\exists\varepsilon>0\text{ s.t. }B_\varepsilon(x)\subset A
\]
Or, put another way, each point has an open ball centered at each $x\in A$ with a radius $\varepsilon$ with is contained in A.
\medskip \\
A set $C\subset X$ is \textbf{closed} if its complement, $C^c=X\setminus C$, is open.
\bigskip \\
\textit{Examples:}
\begin{itemize}
	\item Any open ball, $B_\varepsilon(x)$, is an open set 
	\item Any closed call, $B_\varepsilon[x]$, is a closed set 
	\item Most sets are neither open, nor closed (e.g. $[0,1)$ in $(\R,d_E)$)
	\item The same set can be open in one metric space but closed in another. e.g.:
	\begin{itemize}
		\item $[0,1]$ is not open in $(\R,d_E)$
		\item $[0,1]$ is open in $([0,1],d_E)$
	\end{itemize}
\end{itemize}

\subsection{Intersections and Unions of Open and Closed Sets}
\textit{Theorem}: Let $(X,d)$ be a metric space. Then (note that finite is important: see caveat sub-bullets),
\begin{itemize}
	\item $\emptyset$ and $X$ are simultaneously open and closed in $X$ 
	\item The union of an arbitrary collection of open sets is open
	\item The intersection of a finite collection of open sets is open
		\begin{itemize}
			\item $\union_{n=1}^\infty \left[\frac{1}{n},1-\frac{1}{n}\right]=(0,1)$, is an open set
		\end{itemize}
	\item The union of a finite collection of closed sets is closed
		\begin{itemize}
			\item $\bigcup_{n=1}^\infty \left(1-\frac{1}{n},1)\frac{1}{n}\right)=\{1\}$, is an open set
		\end{itemize}
	\item The intersection of an arbitrary collection of closed sets is closed 
\end{itemize}
Equivalent definition of a \textbf{closed set}: $A\subset X$, where $(X,d)$ is a metric space, is closed if and only if every convergence sequence $\{x_n\}$ contained in $A$ has its limit in $A$


\subsection{Limits of Functions}
Let $(X,d)$ be a metrix space and $A\subset X$.
\smallskip \\
$x_L\in X$ is a \textbf{limit point} of $A$ if $\forall\varepsilon>0$, 
\[
	(B_\varepsilon(x_L)\setminus\{x_L\})\intersect A\neq\emptyset
\]
(i.e. every neighborhood of $x_L$ has a point in $A$ that is not $x_L$)
\medskip \\
Let $(X,d)$ and $(Y,\rho)$ be two metric spaces, $A\subset X$, $f:A\rightarrow Y$, where $x^0$ is a limit point of $A$. A function $f$ has a \textbf{limit} $y^0$ as $x$ approaches $x^0$ if 
\[
	\forall\varepsilon>0\exists\delta>0\text{ s.t. if}x\in A\text{ and }0<d(x,x^0)<\delta\text{, then }\rho(f(x),y^0)<\varepsilon
\]
We write the limit as $\underset{x\rightarrow x^0}{\text{lim }}f(x)=y^0$
\bigskip \\
Theorems of limits: Let $x^0$ be a limit point of $X$. Then,
\begin{itemize}
	\item $\xlmt f(x)=y^0\iff\forall\{x_n\}\in X:x_n\rightarrow x\cap x_n\neq x^0$, $\{f(x_n)\}$ converges to $y^0$ 
	\item $\exists\xlmt f(x)\Rightarrow\exists!\xlmt f(x)$
\end{itemize}


%%%________________________________________________________________%%%

\section{Lecture 4}

\subsection{Continuity}
Let $(X,d)$ and $(Y,\rho)$ be two metric spaces, $A\subset X$, $f:A\rightarrow Y$ is \textbf{continuous} at $x^0$ if
\[
	\forall\varepsilon>0\exists\delta>0\text{ s.t. }d(x,x^0)<\delta\Rightarrow\rho(f(x),f(x^0))<\varepsilon
\]
This requires:
\begin{itemize}
	\item $f(x)$ to be defined 
	\item Either:
		\begin{itemize}
			\item $x^0$ to be an isolated point of $X$ ($\exists\varepsilon>0$ s.t. $B_\varepsilon(x^0)=\{x^0\}$)
			\item $\exists \xlmt f(x)=f(x^0)$
		\end{itemize}
\end{itemize}
Alternative definition (theorem): $f$ is continuous at $x^0$ if and only if either of the following statements is true:
\begin{itemize}
	\item $f(x^0)$ is defined and either $x^0$ is an isolated point or $x^0$ is a limit point of $X$, where $\xlmt f(x)=f(x^0)$
	\item For any sequence $\{x_n\}$ s.t. $x_n\rightarrow x^0$, the sequence $\{f(x_n)\}$ converges to $f(x^0)$
\end{itemize}
\medskip
\textbf{Continuity vis-a-vis open and closed sets:}
A function, $f$ is continous if it is continuous at every point of its domain.
\smallskip \\
Define the \textit{preimage} (pre-image) of a function as: \[ f^{-1}(A) = \{x\in X|f(x)\in A \]
Then, for metric spaces $(X,d)$ and $(Y,\rho)$ and function $f X\rightarrow Y$, we have the theorems:
\begin{itemize}
	\item $f$ is continuous $\iff$ for any closed set $C\subset Y$, $f^{-1}(C)$ is closed in $X$ 
	\item $f$ is continuous $\iff$ for any open set $A\subset Y$, $f^{-1}(A)$ is open in $X$
\end{itemize}

\subsection{Uniform Continuity}
Let $(X,d)$ and $(Y,\rho)$ be metric spaces. $f:X\rightarrow Y$ is \textbf{uniformly continuous} if 
\[
	\forall\varepsilon>0\exists\delta>0\text{ s.t. }d(x,x^0)<\delta\Rightarrow\rho(f(x),f(x^0))<\varepsilon
\]
A critical feature of uniform continuity is that $\delta$ depends \textit{only} on $\varepsilon$ and \textit{cannot} depend on $x^0$.
\smallskip \\
$f$ is uniformly continuous $\Rightarrow$ $f$ is continuous


\subsection{Lipschitz}
Let $(X,d)$ and $(Y,\rho)$ be metric spaces, $f:X\rightarrow Y$, and $E\subset X$. $f$ is \textbf{Lipschitz} on $E$ if
\[
	\exists K>0\text{ s.t. }\rho(f(x),f(y))\leq K d(x,y)\text{ }\forall x,y\in E
\]
$f$ is \textbf{locally Lipschitz} on $E$ if
\[
	\forall x\in E\exists\varepsilon>0\text{ s.t. }f\text{ is Lipschitz on }B_\varepsilon(x)\intersect E
\]
Lipschitz is a stronger form of continuity than uniform continuity.

%%%________________________________________________________________%%%

\section{Lecture 5}

\subsection{Supremum and Infimum}
Let $X\subset\R$. Then $u\in\R$ is an \textbf{upper bound} for $X$ if 
\[
	x\leq u\text{ }\forall x\in X 
\]
and $l\in\R$ is a \textbf{lower bound} for $X$ if 
\[
	l\leq x\text{ }\forall x\in X 
\]
If $X$ has a lower bound, then $X$ is \textbf{bounded below}. If $X$ has an upper bound, then $X$ is \textbf{bounded above}.
\medskip \\
Suppose $X$ is both bounded above and bounded below. The \textbf{supremum} of $X$, written as $\text{sup}X$, is the smallest upper bound for $X$ and satisfies:
\begin{itemize}
	\item $\text{sup}X\geq x$ $\forall x\in X$ 					\indent ($\text{sup}X$ is an upper bound)
	\item $\forall y<\text{sup}X$ $\exists x\in X$ s.t. $x>y$ 	\indent (there is no smaller upper bound)
\end{itemize}
The \textbf{infimum} of $X$, written as $\text{inf}X$, is the largest lower bound of $X$ and satisfies:
\begin{itemize}
	\item $\text{inf}X\leq x$ $\forall x\in X$ 					\indent ($\text{inf}X$ is a lower bound)
	\item $\forall y>\text{inf}X$ $\exists x\in X$ s.t. $x<y$ 	\indent (there is no larger lower bound)
\end{itemize}
\medskip
\textbf{Supremum Property:} Every nonempty set of real numbers that is bounded above has a supremum. This supremum is a real number.

\subsection{Extreme Value Theorem}
Let $f:[a,b]\rightarrow\R$ be a continuous function. Then $F$ attains its maximum and minimum on $[a,b]$:
\begin{align*}
	f(x_M) &= \text{sup}_{x\in[a,b]}f(x) \\
	f(x_m) &= \text{inf}_{x\in[a,b]}f(x) \\
	x_M,x_m &\in[a,b]
\end{align*}

\subsection{Intermediate Value Theorem}
Let $f:[a,b]\rightarrow\R$ be a continuous function. Then for any $\gamma\in[f(a),f(b)]$, $\exists c\in[a,b]$ s.t. $f(c)=\gamma$

\subsection{Monotonic Functions}
$f:\R\rightarrow\R$ is \textbf{monotonically increasing} if $\forall x,y$, $x<y\Rightarrow f(x)<f(y)$.
\smallskip \\
\textit{Theorem:} Let $f:(a,b)\rightarrow\R$ be monotonically increasing. Then $\forall x\in(a,b)$, the following \textbf{one-sided limits} exist:
\[
	f(x^+):=\underset{y\rightarrow x}{\text{lim }}f(y)\text{,  }f(x^-):=\underset{y\rightarrow x^-}{\text{lim }}f(y)
\]
Moreover,
\[
	\text{sup}{f(s)|a<s<x}=f(x^-)\leq f(x)\leq f(x^+)=\text{inf}{f(s)|x<s<b}
\]


%%%________________________________________________________________%%%

\section{Lecture 6}

\subsection{Complete Metric Spaces}
\textbf{Cauchy Sequences}: A sequence $\{x_n\}$ in a metric space $(X,d)$ is Cauchy if
\[
	\forall\varepsilon>0\exists N>0\text{ s.t. }m,n>N\Rightarrow d(x_n,x_m)<\varepsilon
\]
\textit{Theorem}: Every convergent sequence in a metric space is Cauchy. The converse is only true if the metric space is \textbf{complete}.
\medskip \\
A metric space $(X,d)$ is \textbf{complete} if every Cauchy sequence contained in $X$ converges to a point in $X$. E.g. Euclidean space $(\R^m,d_E)$ is complete for any $m$.
\smallskip
If $(X,d)$ is a complete metric space and $Y\subset X$, then $(Y,d)$ is complete if and only if $Y$ is closed.

\subsection{Contraction Mapping Theorem}
Any function $T:X\rightarrow X$ from a metric space to itself is called an \textbf{operator}.
\smallskip \\
An operator $T:X\rightarrow X$ is a \textbf{contraction of modulus} $\mathbf{\beta}$ if $\beta<1$ and
\[
	d(T(x),T(y))\leq \beta d(x,y)\text{ }\forall x,y\in X 
\]
Every contraction is uniformly continuous.
\medskip \\
A \textbf{fixed point} of an operator $T$ is an element $x^*\in X$ s.t. $T(x^*)=x^*$.
\medskip \\
\textbf{Contraction Mapping Theorem:} Let $(X,d)$ be a nonempty, complete metric space where $T:X\rightarrow X$ is a contraction with modulus $\beta<1$. Then:
\begin{itemize}
	\item $T$ has a unique fixed point $x^*$ 
	\item $\forall x_0\in X$, the sequence $\{x_n\}$, where $x_n=T^n(x_0)=T(T(...T(x_0)...))$, converges to $x^*$
\end{itemize}
\medskip
\textbf{Continuous dependence of the fixed point on parameters:} Let $(X,d)$ and $(\Omega,\rho)$ be metric spaces and $T:X\times\Omega\rightarrow X$. For each $\omega\in\Omega$, let $T_\omega:X\rightarrow X$ be defined by $T_\omega(x)=T(x,\omega)$.
\smallskip \\
Suppose $X$ is complete, $T$ is continuous in $\omega$, and $\exists\beta<1$ such that $T_\omega$ is a contraction of modulus $\beta$ $\forall\omega\in\Omega$. Then the fixed point function $x^*:\Omega\rightarrow X$ defined by $x^*(\omega)=T_\omega(x^*(\omega))$ is continuous.
\bigskip \\
\textbf{Blackwell's Sufficient Conditions:} Let $B(X)$ be the set of all bounded functions from $X$ to $\R$ with metric $d_\infty(f,g)=\text{sup}_{x\in X}|f(x)-g(x)|$. Let $T:B(X)\rightarrow B(X)$ satisfy:
\begin{align*}
	\text{Monotonicity: } &f(x)\leq g(x)\text{ }\forall x\in X \Rightarrow (T(f))(x)\leq(T(g))(x)\text{ }\forall x\in X      \\
	\text{Discounting: } &\exists\beta\in(0,1)\text{ s.t. }\forall a\geq 0,x\in X,\text{ }(T(f+a))(x)\leq(T(f))(x)+\beta a 
\end{align*}
Then $T$ is a contraction with modulus $\beta$.


%%%________________________________________________________________%%%

\section{Lecture 7}

\subsection{Compactness}
\textbf{Open Covers}: A collection of sets $\mathcal{U}=\{U_\lambda|\lambda\in\Lambda\}$ in a metric space $(X,d)$ is an \textbf{open cover} of the set $A$ if $U_\lambda$ is open for all $\lambda\in\Lambda$ and $A\subset\union_{\lambda\in\Lambda}U_\lambda$ (Note: $\Lambda$ can be finite, countable, or uncountable)
\smallskip
A set $A$ in a metric space is \textbf{compact} if every open cover of $A$ contains a finite subcover of $A$. i.e., if $\{U_\lambda|\lambda\in\Lambda\}$ is an open cover of A, then 
\[
	\exists n\in\N\text{ s.t. }A\subset U_{\lambda_1}\union U_{\lambda_2}\union...\union U_{\lambda_n}
\]
Examples:
\begin{itemize}
	\item $(0,1)$ is not compact in $\R$:
		\begin{itemize}
			\item $U_n=\left(\frac{1}{n},1\right)$, $n\in\N$ 
			\item $U_n$ is open for any $n\in\N$, $\union_{n=1}^\infty U_n = (0,1)$
			\item However, $\nexists n_1,...,n_k\in\N$ s.t. $U_{n_1}\union U_{n_2}\union ...\union U_{n_k}\supset (0,1)$
		\end{itemize}
	\item $[0,\infty)$ is closed but not compact:
		\begin{itemize}
			\item $U_n=(-1,n)$, $n\in\N$ 
			\item $U_n$ is open for any $n\in\N$, $\union_{n=1}^\infty U_n=(-1,\infty)\supset[0,\infty)$
			\item However, $\nexists n_1,...,n_k\in\N$ s.t. $U_{n_1}\union U_{n_2}\union ...\union U_{n_k}\supset [0,\infty)$
		\end{itemize}
\end{itemize}
\bigskip
\textbf{Properties of Compact Sets}:
\begin{itemize}
	\item Any closed subset of a compact space is compact
	\item If $A$ is a compact subset of a metric space, then $A$ is closed 
	\item If $A$ is a compact subset of a metric space, then $A$ is bounded
\end{itemize}
\bigskip 
\textbf{Compact Subsets in $\R^m$}
\smallskip \\
\textit{Heine-Borel Theorem}: If $A\subset\R^m$, then $A$ is compact if and only if $A$ is closed and bounded.
\smallskip \\
\textbf{NOTE:} It is \textit{not} enough for $A$ to be closed and bounded in a subset of $\R^m$. It must be closed and bounded \textbf{in} $\R^m$.
\medskip \\
\textbf{Sequential Compactness}: A set $A$ in a metric space $(X,d)$ is compact if and only if it is sequentially compact. $A$ is \textbf{sequentially compact} if every sequence of elements of $A$ contains a convergent subsequence whose limit lies in $A$.


\subsection{Extreme Value Theorem, Revisited}
Theorems relating to functions on compact subsets:
\begin{itemize}
	\item Let $(X,d)$ and $(Y,\rho)$ be metric spaces. If $f:X\rightarrow Y$ is continuous and $C$ is a compact set in $(X,d)$, then $f(C)$ is compact in $(Y,\rho)$
	\item (Extreme Value Theorem) If (1) $C$ is a compact set in a metric space, and (2) $f:C\rightarrow\R$ is continuous, then $f$ is bounded on $C$ and attains its maximum and minimum
	\item  Let $(X,d)$ and $(Y,\rho)$ be metric spaces, where $C\subset X$ is compact and $f:C\rightarrow Y$ is continuous. Then $f$ is uniformly continuous on $C$
\end{itemize}


%%%________________________________________________________________%%%

\section{Lecture 8}

\subsection{Vector Spaces}
\textit{Closed under linear compositions, identity elements, null elements, well-behaved operations}
\medskip \\
Def: $V$ is a collection of objects called vectors, which may be added together and multiplied by real numbers, called scalars, satisfying:
\begin{itemize}
	\item $\forall x,y,z\in V, (x+y)+z=x+(y+z)$
	\item $\forall x,y\in V, x+y=y+x$
	\item $\exists!\vec{0}\in V\text{ s.t. }\forall x\in V, x+ \vec{0}=\vec{0} + x=0$
	\item $\forall x\in V \exists!(-x)\in V\text{ s.t. } x+(-x)=\vec{0}$
	\item $\forall\alpha\in\R,x,y\in V, \alpha(x+y)=\alpha x + \alpha y$
	\item $\forall\alpha,\beta\in\R,x\in V, (\alpha+\beta)x=\alpha x + \beta x$
	\item $\forall\alpha,\beta\in\R,x\in V, (\alpha\beta)x=\alpha(\beta x)$
	\item $\forall x\in V, 1\cdot x=x$
\end{itemize}
\medskip 
Let $V$ be a vector space. A \textbf{linear combination} of $x_1,...,x_n\in V$ is a vector of the form
\[
	y=\sum_{i=1}^n \alpha_i x_i\text{, where }\alpha_1,...,\alpha_n \in \R 
\]
$\alpha$ is called the \textbf{coefficient} of $x_i$ in the linear combination
\medskip 
Let $W$ be a subset of $V$. A \textbf{span} of $W$ is the set of all linear combinations of elements of $W$,
\[
	\text{span}W=\left\{ \sum_{i=1}^n \alpha_i x_i | n\in\N,\alpha_1,...,\alpha_n\in\R,x_1,...,x_n\in W\right\}
\]
The set $W\subset V$ spans $V$ if $V=\text{span}W$.

\subsection{Bases}
\textbf{Linear Dependence}: A set $X\subset V$ is \textbf{linearly dependent} if $\exists x_1,...,x_n\in X$, $\alpha_1,...,\alpha_n\in\R$ s.t. $\sum_{i=1}^n \alpha_i^2\neq 0$ and $\sum_{i=1}^n \alpha_i x_i = \vec{0}$.
\smallskip \\
A set $X\subset V$ is \textbf{linearly independent} if $\nexists x_1,...,x_n\in X$, $\alpha_1,...,\alpha_n\in\R$ s.t. $\sum_{i=1}^n \alpha_i^2\neq 0$ and $\sum_{i=1}^n \alpha_i x_i = \vec{0}$
\smallskip \\
i.e. if  $\sum_{i=1}^n \alpha_i x_i = \vec{0}$, then $\alpha_1=...=\alpha_n=0$
\medskip \\
A \textbf{basis} of a vector space $V$ is a linearly independent set of vectors in $V$ that spans $V$.
\medskip \\
\textit{Basis Theorems:}
\begin{itemize}
	\item Let $B$ be a basis for $V$ and enumerate elements of $B$ by a set $\Lambda$ so that $B=\{v_\lambda|\lambda\in\Lambda\}$. Then every vector $x\in V$ has a unique representation as a linear combination of elements of $B$ with finitely many nonzero coefficients
	
	\item Every vector space has a basis. Any two bases of a vector space $V$ have hte same cardinality (i.e. are numerically equivalent)
	
	\item If $V$ is a vector space and $W\subset V$ is linearly independent, then there exists a linearly independent set $B$ such that $W\subset B\subset \text{span}B=V$
\end{itemize}
\medskip
\textbf{Dimension}: Let $V$ be a vector space. The \textbf{dimension} of $V$, denoted $\text{dim}V$, is the cardinality of any basis of $V$. If $\text{dim}V=n$ for some $n\in\N$, then $V$ is finite-dimensional. Otherwise, $V$ is infinite-dimensional.
\smallskip \\
Dimension theorems:
\begin{itemize}
	\item Suppose $\text{dim}V=n\in\N$. If $W\subset V$ and $|W|>n$, where $|W|$ denotes the cardinality of $W$, then $W$ is linearly dependent
	
	\item Suppose $\text{dim}V=n$ and $W\subset V$, $|W|=n$. Then 
		\begin{itemize}
			\item If $W$ is linearly independent, then $\text{span}W=V$, so $W$ is a basis of $V$ 
			\item If $\text{span}W=V$, then $W$ is linearly independent, so $W$ is a basis of $V$
		\end{itemize}
\end{itemize}

\subsection{Linear Transformations}
Let $X$ and $Y$ be vector spaces. We say that $T:X\rightarrow Y$ is a \textbf{linear transformation} if for all $x_1,x_2\in X$, $\alpha_1,\alpha_2\in\R$,
\[
	T(\alpha_1 x_1 + \alpha_2 x_2) = \alpha_1 T(x_1) + \alpha_2 T(x_2)
\]
$L(X,Y)$ is the set of all linear transformations from $X$ to $Y$
\smallskip \\
\textit{Linear transformation theorems:}
\begin{itemize}
	\item $L(X,Y)$ is a vector space 
	\item If $R:X\rightarrow Y$ and $S:Y\rightarrow Z$ are linear transformations, then $S\circ R:X\rightarrow Z$ is a linear transformation
\end{itemize}
\smallskip
\textbf{Image, Kernel, and Rank}: Let $T\in L(X,Y)$. Then,
\begin{itemize}
	\item The \textbf{image} of $T$ is $\text{Im}T:=T(X)=\{T(x)|x\in X\}$
	\item The \textbf{kernel} of $T$ is $\text{ker}T:=\{x\in X|T(x)=\vec{0}\}$
	\item The \textbf{rank} of $T$ is $\text{rank}T:=\text{dim}(\text{Im}T)$
\end{itemize}
\textit{Theorems}:
\begin{itemize}
	\item If $T\in L(X,Y)$, then $\text{Im}T$ and $\text{ker}T$ are vector subspaces of $Y$ and $X$, respectively
	\item Let $X$ be a finite-dimensional vector space and $T\in L(X,Y)$. Then,
		\[
			\text{dim}X=\text{dim}(\text{Ker}T)+\text{rank}T=\text{dim}(\text{Ker}T)+\text{dim}(\text{Im}T)
		\]
\end{itemize}
\medskip
\textbf{Invertible Linear Transformation}: $T\in L(X,Y)$ is \textbf{invertible} if $\exists S:Y\rightarrow X$ s.t
\[
	S(T(x))=x\text{ }\forall x\in X\text{,    } T(S(y))=y\text{ }\forall y\in Y
\]
The transformation $S$ is called the inverse of $T$ and is denoted $T^{-1}$. If $T$ is invertible, then:
\begin{itemize}
	\item $T$ is one-to-one: $\forall x_1\neq x_2$, $T(x_1)\neq T(x_2)$
	\item $T$ is onto: $\forall y\in Y$, $\exists x\in X$ s.t. $T(x)=y$
\end{itemize}
\textit{Invertible Theorems}:
\begin{itemize}
	\item If $T\in L(X,Y)$ is invertible, then $T^{-1}\in L(Y,X)$
	\item $T\in L(X,Y)$ is one-to-one if and only if $\text{ker}T\equiv\{\vec{0}\}$
\end{itemize}


\subsection{Isomorphisms}
Two vector spaces $X$ and $Y$ are \textbf{isomorphic} if there exists an invertible linear function (i.e. one-to-one and onto) from $X$ to $Y$. A function with these properties is called an isomorphism.
\smallskip \\
\textit{Isomorphism Theorems}:
\begin{itemize}
	\item Let $X$ and $Y$ be two vector spaces, and let $V=\{v_\lambda|\lambda\in\Lambda\}$ be a basis for $X$. Then a linear transformation $T:X\rightarrow Y$ is completely defined by its value on $V$. That is:
		\begin{itemize}
			\item Given any set $\{y_\lambda|\lambda\in\Lambda\}\subset Y$, $\exists T\in L(X,Y)$ s.t. $T(v_\lambda)=y_\lambda$ for all $\lambda\in\Lambda$
			\item If $S,T\in L(X,Y)$ and $S(v_\lambda)=T(v_\lambda)$ for all $\lambda\in\Lambda$, then $S=T$ 
		\end{itemize}
		
	\item Two vector spaces $X$ and $Y$ are isomorphic if and only if $\text{dim}X=\text{dim}Y$ (Note: if $\text{dim}X=n$, then $X$ is isomorphic to $\R^n$
\end{itemize}

%%%________________________________________________________________%%%

\section{Lecture 9}

\subsection{Isomorphism between $X$ and $\R^n$}
$V=\{v_1,...,v_n\}\in X$ is a basis of $X$. $\forall x\in X$, $x$ has a unique representation, $x=\sum_{i=1}^n\alpha_i v_i$. The isomorphism from $X$ to $\R^n$ is denoted:
\[
	\text{crd}_V(x)=\colvec{3}{\alpha_1}{\vdots}{\alpha_n}\in\R^n
\]


\subsection{Isomorphism between $L(X,Y)$ and $R^{n\times m}$}
Let:
\begin{align*}
	V=\{v_1,...,v_n\}\in X 	&\text{ be a basis of } X 	\\
	W=\{w_1,...,w_n\}\in Y 	&\text{ be a basis of } Y 	
\end{align*}
For example, 
\[
	T(v_1)=\sum_{i=1}^m \alpha_{i1}w_i,...,T(v_n)=\sum_{i=1}^m \alpha_{in}w_i
\]
Thus, the isomorphism can be represented as:
\[
	\text{mtx}_{W,V}(T)=
	\begin{pmatrix}
		\alpha_{11} & \alpha_{12} 	& \cdots 	& \alpha_{1n} 	\\
		\vdots 		& \vdots 		& \ddots	& \vdots		\\
		\alpha_{m1} & \alpha_{m2}	& \cdots 	& \alpha_{mn}
	\end{pmatrix}
	\in M_{m\times n}
\]
\textbf{Matrix Representation of a Composition of Linear Functions}: \\
Let 
\begin{align*}
	U\subset X &\text{ be a basis of } X \\
	V\subset Y &\text{ be a basis of } Y \\
	W\subset Z &\text{ be a basis of } Z \\
	S\in L(X,Y),&T\in L(Y,Z)
\end{align*}
Then,
\[
	\text{mtx}_{W,V}(T)\cdot\text{mtx}_{V,U}(S)=\text{mtx}_{W,U}(T\circ S)
\]

\subsection{Change of Basis}
\begin{itemize}
	\item $\text{dim}X=n$, $T\in L(X,X)$
	\item $\text{mtx}_V(T)\equiv\text{mtx}_{V,V}(T)$
\end{itemize}
If we change basis from $V$ to $W$, then:
\[
	\text{mtx}_V(T)=\text{mtx}_{V,W}(id)\cdot\text{mtx}_W(T)\cdot\text{mtx}_{W,V}(id)
\]
Where:
\begin{align*}
	&\text{mtx}_{V,W}(id)\cdot\text{mtx}_{W,V}(id)=\text{mtx}_{V}(id)=I \\
	&\text{mtx}_{V,W}(id) = [\text{mtx}_{W,V}(id)]^{-1}
\end{align*}
Thus, $\text{mtx}_V(T)=P^{-1}\cdot\text{mtx}_W(T)\cdot P$, where $P=\text{mtx}_{W,V}(id)$

\subsection{Similarity}
$A,B\in M_{n\times n}$ are \textbf{similar} if $A=P^{-1} BP$ for some invertible matrix $P$ 
\smallskip \\
\textit{Theorem}: IF $\text{dim}X=n$, then:
\begin{itemize}
	\item If $T\in L(X,X)$, then any two matrix representations of $T$ are similar 
	\item Two similar matrices represent the same linear transformation $T$, relative to suitable bases
\end{itemize}



%%%________________________________________________________________%%%
















\end{document}