%%% Econ709: Econometrics
%%% Fall 2020
%%% Danny Edgel
%%%
% Due on Canvas Sunday, October 18th, 11:59pm Central Time
%%%

%%%
%							PREAMBLE
%%%

\documentclass{article}

%%% declare packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{bm}
\usepackage{bbm}
\usepackage{changepage}
\usepackage{centernot}
\usepackage{graphicx}
\usepackage[shortlabels]{enumitem}
\usepackage{fancyhdr}
	\fancyhf{} % sets both header and footer to nothing
	\renewcommand{\headrulewidth}{0pt}
    \rfoot{Edgel, \thepage}
    \pagestyle{fancy}
	
%%% define shortcuts for set notation
\newcommand{\N}{\mathcal{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\union}{\bigcup}
\newcommand{\intersect}{\bigcap}
\newcommand{\lmt}{\underset{x\rightarrow\infty}{\text{lim }}}
\newcommand{\neglmt}{\underset{n\rightarrow-\infty}{\text{lim }}}
\newcommand{\zerolmt}{\underset{x\rightarrow 0}{\text{lim }}}
\newcommand{\usmax}{\underset{1\leq k \leq n}{\text{max }}}
\newcommand{\intinf}{\int_{-\infty}^{\infty}}
\newcommand{\olx}[1]{\overline{X}_{#1}}
\newcommand{\oly}[1]{\overline{Y}_{#1}}
\newcommand{\est}[1]{\frac{1}{#1}\sum_{i=1}^{#1}}
\newcommand{\sumn}{\sum_{i=1}^{n}}
\newcommand{\loge}[1]{\text{log}\left(#1\right)}
\renewcommand{\Pr}[1]{\text{Pr}\left(#1\right)}

%%% define column vector command (from Michael Nattinger)
\newcount\colveccount
\newcommand*\colvec[1]{
        \global\colveccount#1
        \begin{pmatrix}
        \colvecnext
}
\def\colvecnext#1{
        #1
        \global\advance\colveccount-1
        \ifnum\colveccount>0
                \\
                \expandafter\colvecnext
        \else
                \end{pmatrix}
        \fi
}

\makeatletter
\let\amsmath@bigm\bigm

\renewcommand{\bigm}[1]{%
  \ifcsname fenced@\string#1\endcsname
    \expandafter\@firstoftwo
  \else
    \expandafter\@secondoftwo
  \fi
  {\expandafter\amsmath@bigm\csname fenced@\string#1\endcsname}%
  {\amsmath@bigm#1}%
}


%________________________________________________________________%

\begin{document}

\title{	Problem Set \#6 }
\author{ 	Danny Edgel 										\\ 
			Econ 709: Economic Statistics and Econometrics I	\\
			Fall 2020											\\
		}
\maketitle\thispagestyle{empty}

%%%________________________________________________________________%%%

\noindent\textit{Collaborated with Sarah Bass, Emily Case, Michael Nattinger, and Alex Von Hafften}
%%%________________________________________________________________%%%

\section*{Question 1}
Say $P(X=1)=p$ and $P(X=0)=1-p$, where $0<p<1$.
\begin{itemize}
	\item[(a)] Say $f(x)=p^x(1-p)^{1-x}$. Then,
		\begin{align*}
			f(0) &= p^0(1-p)^{1-0} = 1-p = P(X=0)	\\
			f(1) &= p^1(1-p)^{1-1} = p = P(X=1)
		\end{align*}
	\item[(b)] 
		\[
			\ell_n = \sum_{i=1}^n \loge{f(x_i)} = \sum_{i=1}^nx_i\loge{p} + (1-x_i)\loge{1-p} = n\loge{p} + \loge{1-p}\sumn1-x_i
		\]
	\item[(c)] To find $\hat{p}$, we simply maximize $\ell_n$ with repspect to $p$:
		\begin{align*}
			\frac{\partial\ell_n}{\partial p} &= \frac{1}{p}\sumn x_i - \frac{1}{1-p}\sumn 1-x_i = 0	\\
			\frac{n}{p}\overline{X}_n &= \frac{n}{1-p} - \frac{n}{1-p}\overline{X}_n	\\
			\frac{p-1}{p}\olx{n} &= 1 - \olx{n} \\
			\left(\frac{p-1}{p}+1\right)\olx{n} &= 1 \\
			\frac{1}{p}\olx{n} &= 1 \\
			\hat{p}_n &= \olx{n}
		\end{align*}
\end{itemize}


%%%________________________________________________________________%%%

\section*{Question 2}
$X\sim f(x)=\frac{\alpha}{x^{1+\alpha}}$, $x\geq 1$
\begin{enumerate}[(a)]
	\item The log-likelihood function is:
		\[
			\ell_n = \sum_{i=1}^n\loge{f(x_i)} = \sumn\loge{\alpha}-(1+\alpha)\loge{x_i} = n\loge{\alpha} - (1+\alpha)\sumn\loge{x_i}
		\]
		
	\item To find $\hat{\alpha}$, we simply maximize $\ell_n$ with repspect to $\alpha$:
		\begin{align*}
			\frac{\partial\ell_n}{\partial\alpha} &= \frac{n}{\alpha} - \sumn\loge{x_i} = 0 \\
			\frac{n}{\hat{\alpha}} &= \sumn\loge{x_i}	\\
			\hat{\alpha}_n^{-1} &= \frac{1}{n}\sumn\loge{x_i}
		\end{align*}
\end{enumerate}


%%%________________________________________________________________%%%

\section*{Question 3}
$X\sim f(x)=\left[\pi(1+(x-\theta)^2)\right]^{-1}$, $x\in\R$
\begin{enumerate}[(a)]
	\item The log-likelihood function is:
		\[
			\ell_n = \sum_{i=1}^n\loge{f(x_i)} = \sumn\loge{\pi}+\loge{1+(x_i-\theta)^2} = -n\loge{\pi}-\sumn\loge{1+(x_i-\theta)^2}
		\]
		
	\item The first-order condition for the MLE $\hat{\theta}$ is:
		\[
			\frac{\partial\ell_n}{\partial\theta} = \sumn\frac{2(x_i-\hat{\theta}_n)}{1+(x_i-\hat{\theta}_n)}=0
		\]
\end{enumerate}


%%%________________________________________________________________%%%

\section*{Question 4}
$X\sim f(x)=\frac{1}{2}\text{exp}(-|x-\theta|)$, $x\in\R$
\begin{enumerate}[(a)]
	\item The log-likelihood function is:
		\[
			\ell_n = \sum_{i=1}^n\loge{f(x_i)} = \sumn\loge{\frac{1}{2}}-|x_i-\theta| = n\loge{\frac{1}{2}}-\sumn-|x_i-\theta|
		\]
		
	\item The MLE will be $\hat{\theta}_n$ that minimizes $\sumn|x_i-\hat{\theta}_n|$, so we want to choose theta that will minimize the sum of the absolute deviations from $X_i$. We already know that this value is $\est{n}x_i=\olx{n}$. Thus,
		\[
			\hat{\theta}_n = \est{n}X_i
		\]
\end{enumerate}


%%%________________________________________________________________%%%

\section*{Question 5}
$f(x)=\alpha x^{-1-\alpha}$, $x\geq 1$. $I$ is defined as:
\[
	I_0 = -E\left[\frac{\partial^2 \loge{f(x|\theta_0)}}{\partial\theta\partial\theta'}\right]
\]
Thus, given $f(x|\alpha)$:
\begin{align*}
	\loge{f(x|\alpha)} &= \loge{\alpha} - (1-\alpha)\loge{x}	\\
	\frac{\partial\loge{f(x|alpha)}}{\partial\alpha} &= \frac{1}{\alpha} + \loge{x}	\\
	\frac{\partial^2\loge{f(x|alpha)}}{\partial\alpha^2} &= -\frac{1}{\alpha^2}
\end{align*}
Therefore,
\[
	I = \frac{1}{\alpha^2}
\]


%%%________________________________________________________________%%%

\section*{Question 6}
$f(x)=\theta\text{exp}(-\theta x)$, $x\geq 0$, $\theta > 0$
\begin{enumerate}[(a)]
	\item The Cramer-Rao Lower Bound (CRLB) is equal to $(nI_0)^{-1}$. then,
		\begin{align*}
			\loge{f(x)} &= \loge{\theta}-\theta x \\
			\frac{\partial\loge{f(x)}}{\partial\theta} &= \frac{1}{\theta}-x \\
		I =	\frac{\partial^2\loge{f(x)}}{\partial\theta^2} &= -\frac{1}{\theta^2}	\\
			\text{CRLB }&= \frac{1}{n}\theta^2
		\end{align*}
		
	\item From a previous problem, $\hat{\theta}_n=(\olx{n})^{-1}$. Then $\hat{\theta}_n=g(\olx{n})$. By the central limit theorem,
		\[
			\sqrt{n}(\olx{n}-\mu)\rightarrow_d\N(0,\sigma^2)
		\]
		Where $Var(X)=\sigma^2$. Then, by the delta method,
		\[
			\sqrt{n}(\hat{\theta}_n-\theta)\rightarrow_d g'(\olx{n})\N(0,\sigma^2) = -\olx{n}^{-2}\N(0,\sigma^2)
		\]
		Thus,
		\[
			\hat{\theta}_n\rightarrow_d\N\left(\theta,\frac{\sigma^2}{n\olx{n}^4}\right)
		\]
		Where $E(\olx{n})=\frac{1}{\theta_0}$ and, because $X\sim\theta\text{exp}(-\theta x)$, $\sigma^2=\frac{1}{\theta_0^2}$. Therefore,
		\[
			\hat{\theta}_n\rightarrow_d\N\left(\theta,\frac{1}{n}\theta_0^2\right)
		\]
		
	\item From section 6, $\sqrt{n}(\hat{\theta}_n-\theta_0)\rightarrow_d\N(0,I_0^{-1})$. Then,
		\[
			\sqrt{n}(\hat{\theta}_n-\theta_0)\rightarrow_d\N(0,\theta^2)
		\]
		Which is equal to the answer I got in (b).
\end{enumerate}


%%%________________________________________________________________%%%

\section*{Question 7}
\begin{enumerate}[(a)]
	\item In question 1, we found $\hat{p}_n=\olx{n}$. Then $\hat{p}_n=g(\olx{n})=\olx{n}$, so by the delta method,
		\[
			\sqrt{n}(\olx{n}-\mu)\rightarrow_d\N(0,\sigma^2)\Rightarrow\sqrt{n}(\hat{p}_n-p)\rightarrow_d\N(0,\sigma^2)
		\]
		so $V=Var(X_i)=\sum_{i=1}^n(X_i-\olx{n})^2$.
		
		\item By the weak law of large numbers, $\est{n}X_i\rightarrow_p E(X)$ and $\sum_{i=1}^n(X_i-E(X))^2 = E(X-E(X))^2$, so $V$ is a consistent esimator.
		
		\item Recall that $\hat{p}_n=\olx{n}$. We know that $Var(\olx{n})=\frac{1}{n}\sigma^2$, and our estimator for $\sigma^2$ is given by ${\hat{\sigma}_n=\est{n}(X_i-\olx{n}}$. Thus,
			\[
				s(\hat{p}_n) = \frac{1}{n^2}\sum_{i=1}^n(X_i-\hat{p}_n)^2
			\]
\end{enumerate}


%%%________________________________________________________________%%%

\section*{Question 8}
\begin{enumerate}[(a)]
	\item Let $F_X$ be the CDF of $\text{Uniform}[0,\theta]$. The PDF of any uniform distribution over $[A,B]$ is ${f(x)=\frac{1}{B-A}}$, so we can derive:
		\[
			F_X(c) = \int_0^cf(x)dx = \int_0^c\frac{1}{\theta}dx = \frac{x}{\theta}|^c_0 =
				\begin{cases}
					0, 					&c<0			\\		
					\frac{c}{\theta}, 	&c\in[0,\theta] \\
					1, 					&c>\theta
				\end{cases}
		\]
		
	\item From the definition of $F_{n(\hat{theta}_n-\theta)}(x)$, we can solve:
		\begin{align*}
			F_{n(\hat{theta}_n-\theta)}(x) 	&= \Pr{\underset{i=1,...,n}{\text{max}}(n(X_i-\theta))\leq x}	\\
											&= \prod_{i=1}^n\Pr{n(X_i-\theta)\leq x}						\\
											&= \prod_{i=1}^n\Pr{X_i\leq\frac{x}{n}+\theta}					\\
											&= \prod_{i=1}^n F_X(\theta+\frac{x}{n})						\\
			F_{n(\hat{theta}_n-\theta)}(x) 	&=\left(F_X(\theta+\frac{x}{n})\right)^n
		\end{align*}
		
	\item Knowing that $\lmt(1+\frac{y}{n})=e^y$ $\forall y\in\R$,
		\[
			\lmt F_{n(\hat{\theta}_n-\theta)}(x) = \lmt(F_X(\theta+\frac{x}{n}))^n =
				\begin{cases}
					\lmt 0^n , &\theta+\frac{x}{n}<0 	\\
					\lmt \left(\frac{\theta + \frac{x}{n}}{\theta}\right)^n, &\theta+\frac{x}{n}\in[0,\theta]	\\
					\lmt 1^n, &\theta + \frac{x}{n}>\theta
				\end{cases}
		\]
		Simplifying and recognizing that ${\lmt \left(\frac{\theta + \frac{x}{n}}{\theta}\right)^n = \lmt\left(1+\frac{x/\theta}{n}\right)^n}$, we get:
		\[
			\frac{\partial}{\partial x}\left(F_{n(\hat{theta}_n-\theta)}(x)\right) = 
				\begin{cases}
					0, &x<-n\theta \\
					\frac{1}{\theta}e^\frac{x}{\theta}, &x\in[-n\theta,0] \\
					0, x>0
				\end{cases}
		\]
		Thus, $n(\hat{\theta}_n-\theta)\rightarrow_d f(-x|\theta)$, where $f(-x|\theta)$ is an exponential distribution with parameter $\frac{1}{\theta}$.
\end{enumerate}



%%%________________________________________________________________%%%

\section*{Question 9}
$X\sim\N(\mu,\sigma^2)$, H$_0$: $\mu=1$, H$_1$: $\mu\neq 1$. To test this hypothesis, collect an i.i.d. sample, $\{X_1,...,X_n\}$ and calculate:
\begin{align*}
	&T = \frac{\sqrt{n}(\olx{n}-1)|}{s_x}\text{, where } \olx{n}=\est{n}X_i\text{ and } s_x=\frac{1}{n-1}\sum_{i=1}^n(X_i-\olx{n})^2 \\
	&t_{\frac{\alpha}{2},n-1}\text{, where } t_{\frac{\alpha}{2},n-1} \text{ is the }\left(1-\frac{\alpha}{2}\right)^{\text{th}}\text{ percentile of }t_{n-1}
\end{align*}
Then, choose $\alpha = 0.05$. If $T>t_{\frac{\alpha}{2},n-1}$, then reject H$_0$. Otherwise, do not reject H$_0$.

%%%________________________________________________________________%%%

\section*{Question 10}
$X\sim\N(\mu,1)$, H$_0$: $\mu\in\{0,1\}$, H$_1$: $\mu\notin\{0,1\}$, where:
\[
	T = \text{min}\left\{|\sqrt{n}\olx{n}|,|\sqrt{n}(\olx{n}-1)|\right\}
\]
And the critical value, $c$, is the $(1-\alpha)^\text{th}$ quantile of ${\text{min}\left\{|Z|,|Z-\sqrt{n}|\right\}}$, where $Z\sim\N(0,1)$.
\medskip \\
If $\mu=0$, then, by the central limit theorem (CLT),
\begin{align*}
	\sqrt{n}\olx{n} 	&= \sqrt{n}(\olx{n}-E(\olx{n}))\rightarrow_d\N(0,1) 			\\
	\sqrt{n}(\olx{n}-1) &= \sqrt{n}\olx{n} - \sqrt{n}\rightarrow_d\N(-\sqrt{n},1)
\end{align*}
And if $\mu=1$, then,
\begin{align*}
	\sqrt{n}(\olx{n}-1) &= \sqrt{n}(\olx{n}-E(\olx{n}))\rightarrow_d\N(0,1) 			\\
	\sqrt{n}\olx{n}		&= \sqrt{n}(\olx{n}-1) + \sqrt{n}\rightarrow_d\N(\sqrt{n},1)
\end{align*}
Note that, since the normal distribution is symmetric and $Z$ is mean zero, $Z$ and $-Z$ have the same distribution. Further, we can define $Z=\sqrt{n}\olx{n}$. Then, we can solve:
\begin{align*}
	\Pr{T>c|\mu=0}	&= \Pr{\text{min}\{|\sqrt{n}\olx{n}|,|\sqrt{n}(\olx{n}-1)|\}>c|\mu=0\}}	\\
					&= \Pr{\text{min}\{|Z|,|Z-\sqrt{n}|>c\}}								\\
					&= \alpha \text{ (by construction)}										\\
	\Pr{T>c|\mu=1}	&= \Pr{\text{min}\{|\sqrt{n}\olx{n}|,|\sqrt{n}(\olx{n}-1)|\}>c|\mu=0\}}	\\
					&= \Pr{\text{min}\{|Z+\sqrt{n}|,|Z|\}>c}								\\
					&= \Pr{\text{min}\{|(-1)(-Z-\sqrt{n})|,|Z|\}>c}							\\
					&= \Pr{\text{min}\{|Z-\sqrt{n}|,|Z|\}>c}								\\
					&= \alpha
\end{align*}
$\therefore$ $\Pr{T>c|\mu=0}=\Pr{T>c|\mu=1}=\alpha$


%%%________________________________________________________________%%%




\end{document}












