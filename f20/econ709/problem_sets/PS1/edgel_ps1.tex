%%% Econ709: Econometrics
%%% Fall 2020
%%% Danny Edgel
%%%
% Due on Canvas Wednesday September 14, 11:59pm Central Time
%%%

%%%
%							PREAMBLE
%%%

\documentclass{article}

%%% declare packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{bm}
\usepackage{changepage}
\usepackage{centernot}
\usepackage{graphicx}
\usepackage{fancyhdr}
	\fancyhf{} % sets both header and footer to nothing
	\renewcommand{\headrulewidth}{0pt}
    \rfoot{Edgel, \thepage}
    \pagestyle{fancy}
	
%%% define shortcuts for set notation
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\union}{\bigcup}
\newcommand{\intersect}{\bigcap}
\newcommand{\lmt}{\underset{x\rightarrow\infty}{\text{lim }}}
\newcommand{\neglmt}{\underset{x\rightarrow-\infty}{\text{lim }}}
\newcommand{\zerolmt}{\underset{x\rightarrow 0}{\text{lim }}}
\newcommand{\usmax}{\underset{1\leq k \leq n}{\text{max }}}

%%% define column vector command (from Michael Nattinger)
\newcount\colveccount
\newcommand*\colvec[1]{
        \global\colveccount#1
        \begin{pmatrix}
        \colvecnext
}
\def\colvecnext#1{
        #1
        \global\advance\colveccount-1
        \ifnum\colveccount>0
                \\
                \expandafter\colvecnext
        \else
                \end{pmatrix}
        \fi
}

\makeatletter
\let\amsmath@bigm\bigm

\renewcommand{\bigm}[1]{%
  \ifcsname fenced@\string#1\endcsname
    \expandafter\@firstoftwo
  \else
    \expandafter\@secondoftwo
  \fi
  {\expandafter\amsmath@bigm\csname fenced@\string#1\endcsname}%
  {\amsmath@bigm#1}%
}


%________________________________________________________________%

\begin{document}

\title{	Problem Set \#1 }
\author{ 	Danny Edgel 										\\ 
			Econ 709: Economic Statistics and Econometrics I	\\
			Fall 2020											\\
		}
\maketitle\thispagestyle{empty}

%%%________________________________________________________________%%%

\section*{Question 1}
\textbf{For two events,} $A,B\in S$\textbf{, prove that} $A\union B=(A\intersect B)\union((A\intersect B^c)\union(B\intersect A^c))$\textbf{.}
\medskip \\
\textit{Proof.}
\begin{enumerate}
	\item $(A\intersect B)\union((A\intersect B^c)\union(B\intersect A^c)) = ((A\intersect B)\union(A\intersect B^c))\union((A\intersect B)\union(B\intersect A^c))$
	\item $B\union B^c=S$, so $(A\intersect B)\union(A\intersect B^c)=A$
	\item $A\union A^c=S$, so $(A\intersect B)\union(B\intersect A^c)=B$
	\item Given $2$ and $3$, $((A\intersect B)\union(A\intersect B^c))\union((A\intersect B)\union(B\intersect A^c)) = A\union B$
\end{enumerate}
$\therefore$ $A\union B = (A\intersect B)\union((A\intersect B^c)\union(B\intersect A^c))$ $\blacksquare$

%%%________________________________________________________________%%%

\section*{Question 2}
\textbf{Prove that} $P(A\union B)=P(A)+P(B)-P(A\intersect B)$\textbf{.}
\medskip \\
\textit{Proof.}
\begin{enumerate}
	\item $A\union B=A\union(B\intersect A^c)$. $A$ and $(B\intersect A^c)$ are disjoint, so $P(A\union B)=P(A) + P(B\union A^c)$
	\item $A=(A\intersect B)\union(A\intersect B^c)$. Each of these are disjoint, so $P(A)=P(A\intersect B) + P(A\intersect B^c)$
	\item Given $1$ and $2$, 
		\begin{align*}
			P(A\union B)						&= P(A\intersect B)+P(A\intersect B^c)+P(B\intersect A^c)								\\
			P(A\union B) + P(A\intersect B)		&= (P(A\intersect B^c) + P(A\intersect B)) + (P(B\intersect A^c) + P(A\intersect B))	\\
			P(A\union B) + P(A\intersect B)		&= P(A) + P(B)																			\\
			P(A\union B)						&= P(A) + P(B) - P(A\intersect B)
		\end{align*}
\end{enumerate}
$\therefore$ $P(A\union B)= P(A) + P(B) - P(A\intersect B)$ $\blacksquare$

%%%________________________________________________________________%%%

\section*{Question 3}
\textbf{Suppose that the unconditional probability of a disease is 0.0025. A screening test for this disease has a detection rate of 0.9, and has a false positive rate of 0.01. Given that the screening test returns positive, what is the conditional probability of having the disease?}
\medskip \\
Let $A$ be the event of having the disease and $P$ be the event of a positive test result. Then the conditional probability of having the disease in the event of a positive test result is given by:
\[
	P(A|P) = \frac{P(A\intersect P)}{P(P)} = \frac{P(P|A)P(A)}{P(P|A)P(A) + P(P|A^c)P(A^c)}
\]
Where:
\begin{itemize}
	\item $P(P|A)$ is the probability of a positive test result conditional on having the disease. This is given as $0.9$
	\item $P(P|A)P(A)$ is the probability of having the disease and getting a positive result. $P(A)$ is given as $0.0025$
	\item $P(P|A^c)P(A^c)$ is the probability of not having the disease and getting a false positive. $P(P|A^c)$ is given as $0.01$
\end{itemize}
Thus, we can derive:
\[
	P(A|P) = \frac{P(P|A)P(A)}{P(P|A)P(A) + P(P|A^c)P(A^c)}\frac{(0.9)(0.0025)}{(0.9)(0.0025) + (0.01)(1-0.0025)}\approx0.1840491
\]
Therefore, the probability of having the disease, conditional on a positive test result, is roughly $0.184$.


%%%________________________________________________________________%%%

\section*{Question 4}
\textbf{Suppose that a pair of events} $A$ \textbf{and }$B$\textbf{ are mutually exclusive, i.e.,} $A\intersect B=\emptyset$\textbf{, and that} $P(A)>0$\textbf{ and }$P(B)>0$\textbf{. Prove that} $A$ \textbf{and} $B$ \textbf{are not independent.}
\medskip \\
By definition of independence, if $A$ and $B$ are independent, then $P(A\intersect B)=P(A)P(B)$. However, it is given that $A\intersect B=\emptyset$, $P(A)>0$, and $P(B)>0$. Then $P(A)P(B)>0$. Thus,
\[
	P(A\intersect B)=P(\emptyset)=0 \neq P(A)P(B)
\]
$\therefore$ $A$ and $B$ are not independent $\blacksquare$

%%%________________________________________________________________%%%

\section*{Question 5}
\textbf{Consider the experiment of tossing two dice. Let} $A=\{\text{First die is }6\},B=\{\text{Second die is }6\}$, and $C=\{\text{Both dice are the same}\}$\textbf{.}
\subsection*{(a)}
\textbf{Show that} $A$ \textbf{and} $B$ \textbf{are independent (unconditionally), but} $A$ \textbf{and} $B$ \textbf{are dependent given} $C$\textbf{.}
\medskip \\
Each die roll has one of six possible outcomes, so $P(A)=P(B)=\frac{1}{6}$. The probability that $A$ and $B$ both occur ($A\intersect B$) is one of $36$ possible outcomes when two die are rolled. Then,
\[
	P(A\intersect B)=\frac{1}{36}=\left(\frac{1}{6}\right)\left(\frac{1}{6}\right)=P(A)P(B)
\]
Thus, $A$ and $B$ are independent.
\smallskip \\
Since $A\intersect B$ is one of six possibilities in the event of $C$, so $P(A\intersect B|C)=\frac{1}{6}$. However, $C$ does not change the probability of $A$ or $B$, so $P(A|C)=P(B|C)=\frac{1}{6}$. Thus, $P(A\intersect B|C)\neq P(A|C)P(B|C)$, and $A$ and $B$ are dependent given $C$.


\subsection*{(b)}
\textbf{Given the urn experiment (see 5(b)), Show that} $A$ \textbf{and} $B$ \textbf{are not independent, but are conditionally independent given} $C$\textbf{.}
\medskip \\
Urn 1 and urn 2 are chosen with equal probability $\left(\text{i.e. }P(C)=P(C^c)=\frac{1}{2}\right)$. If the first urn is chosen, two black balls are drawn in $81$ of $100$ possible outcomes. If urn $2$ is chosen, two black balls are drawn in $19$ of $100$ outcomes. Thus,
\[
	P(A\intersect B)=\frac{1}{2}\left(\frac{81}{100}\right)+\frac{1}{2}\left(\frac{19}{100}\right)=\frac{1}{2}
\]
Meanwhile, drawing a black ball is one of nine possibilities if urn 1 is chosen and one of ten possibilities if urn two is chosen. This is true on either the first or second draw. Then,
\[
	P(A) = P(B) = \frac{1}{2}\left(\frac{9}{10}\right)+\frac{1}{2}\left(\frac{1}{10}\right)=\frac{1}{2}
\]
Therefore, $P(A)P(B)=\frac{1}{4}\neq P(A\intersect B)$, so $A$ and $B$ are not independent.
\smallskip \\
As I mentioned above, two consecutive draws of a black ball occurs in 81 of 100 possibilities if urn 1 is chosen. Thus, $P(A\intersect B|C)=\frac{9}{10}$. Since each of the two draws yield a black ball in nine of outcomes, $P(A|C)=P(A|B)=\frac{9}{10}$. Then,
\[
	P(A|C)P(A|B)=\left(\frac{9}{10}\right)\left(\frac{9}{10}\right)=\frac{81}{100}=P(A\intersect B|C)
\]
So $A$ and $B$ are conditionally independent, given $C$.

%%%________________________________________________________________%%%

\section*{Question 6}
\textbf{Prove that if} $X\sim F_X$ \textbf{and} $Y\sim F_Y$\textbf{, then} $P(X>t)\geq P(Y>t)\text{, }\forall t$ \textbf{and} $P(X>t)> P(Y>t)$\textbf{, for some} $t$\textbf{.}
\medskip \\
$P(X>t)=1-F_X(t)$ and $P(Y>T)=1-F_Y(t)$, so given that $F_X(t)\leq F_Y(t)$ $\forall t$, we can solve:
\begin{align*}
	F_X(t)			&\leq F_Y(t)			\\
	F_X(t)-1		&\leq F_Y(t)-1			\\
	1-F_X(t)		&\geq 1-F_Y(t)			\\
	P(X>t)			&\geq P(Y>t)
\end{align*}
Therefore, $P(X>t) \geq P(Y>t)$ for all $t$. We also know that $\exists t_0$ such that $F_X(t_0)< F_Y(t_0)$. Using the same process, we can derive that $P(X>t_0)> P(Y>t_0)$:
\begin{align*}
	F_X(t_0)		&< F_Y(t_0)			\\
	F_X(t_0)-1		&< F_Y(t_0)-1		\\
	1-F_X(t_0)		&> 1-F_Y(t_0)		\\
	P(X>t_0)		&> P(Y>t_0)
\end{align*}
%%%________________________________________________________________%%%

\section*{Question 7}
\textbf{Show that the function}\[F_X=\begin{cases}0 &\text{if } x<0 \\ 1-e^{-x} &\text{if } x\geq 0\end{cases}\]\textbf{is a CDF, and find } $f_X(x)$ \textbf{and} $F_X^{-1}(y)$\textbf{.}
\medskip \\
I will show that $F_X$ has each of the properties of a CDF:
\begin{enumerate}
	\item $\neglmt F(x)= 0$ and $\lmt F(x)= 1$
	\smallskip \\
	$F(x)=0$ for all $x<0$, so $\neglmt F(x)= 0$. $\lmt e^{-x} = 0$, so  $\lmt(1-e^{-x})= 1$
	
	\item $F(x)$ is non-decreasing
	\smallskip \\
	$F(0)=1-e^0=1-1=0$, and $e^{-x}$ is a decreasing function, so $1-e^{-x}$ is an increasing function for $x\geq 0$. Since $F(x)=0$ $\forall x\in(-\infty,0]$, $F(x)$ is non-decreasing on $(-\infty,\infty)$.
	
	\item $F(x)$ is right-continuous
	\smallskip \\
	$1-e^{-x}$ is continuous for all $x$, and $\underset{x\rightarrow x_0^-}F(x)=\underset{x\rightarrow x_0^+}F(x)=0$, so $F(x)$ is also continuous.
	
\end{enumerate}
Thus, $F_X$ is a CDF.
\medskip \\
\[
	f_X(x)=\frac{d}{dX} F_X=  \begin{cases}\frac{d}{dx} 0 &\text{if } x<0 \\ \frac{d}{dx} (1-e^{-x}) &\text{if } x\geq 0\end{cases}
\]
Where $\frac{d}{dx} (1-e^{-x})=e^{-x}$, so:
\[
	f_X(x)=\begin{cases}0 &\text{if } x<0 \\ e^{-x} &\text{if } x\geq 0\end{cases}
\]
Let $y=F_X$. Then, for $x\geq 0$,
\begin{align*}
	y			&= 1-e^{-x}	\\
	y-1			&= -e^{-x}	\\
	1-y			&= e^{-x}	\\
	ln(1-y)		&= -x 		\\
	-ln(1-y)	&= x
\end{align*}
Thus, $F_X^{-1}(y) = -ln(1-y)$, $y\in[0,1)$

%%%________________________________________________________________%%%


\end{document}












